{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install aflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pymatgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install \"dask[complete]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only when running first time -----------------------------\n",
    "\n",
    "from aflow import *\n",
    "import pickle\n",
    "\n",
    "global bimetallics\n",
    "bimetallics = []\n",
    "checked_result = []\n",
    "with open('bimetallics.pkl','wb') as file_handle:\n",
    "    pickle.dump(bimetallics,file_handle)\n",
    "\n",
    "actives = ['Pd', 'Pt', 'Rh', 'Ru', 'Ag', 'Ir','Pd\\n', 'Pt\\n', 'Rh\\n', 'Ru\\n', 'Ag\\n', 'Ir\\n']\n",
    "hosts = ['Zn', 'Cd', 'Ga', 'Al', 'In','Zn\\n', 'Cd\\n', 'Ga\\n', 'Al\\n', 'In\\n']\n",
    "result = search(\n",
    "                ).select(K.nspecies==2\n",
    "                ).filter(K.enthalpy_formation_atom<-0.1)\n",
    "with open('all_results.pkl','wb') as file_handle:\n",
    "    pickle.dump(result,file_handle)\n",
    "with open('checked_results.pkl','wb') as file_handle:\n",
    "    pickle.dump(checked_result,file_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aflow import *\n",
    "import pickle\n",
    "\n",
    "global bimetallics,result,checked_result\n",
    "with open('bimetallics.pkl','rb') as file_handle:\n",
    "    bimetallics = pickle.load(file_handle)\n",
    "with open('all_results.pkl','rb') as file_handle:\n",
    "    result = pickle.load(file_handle)\n",
    "with open('checked_results.pkl','rb') as file_handle:\n",
    "    checked_result = pickle.load(file_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_bimetallic(r):\n",
    "    if r.species[0] in hosts and r.species[1] in actives:\n",
    "        bimetallics.append(r)\n",
    "        with open('bimetallics.pkl','wb') as file_handle:\n",
    "            pickle.dump(bimetallics,file_handle)\n",
    "    elif r.species[1] in hosts and r.species[0] in actives:\n",
    "        bimetallics.append(r)\n",
    "        with open('bimetallics.pkl','wb') as file_handle:\n",
    "            pickle.dump(bimetallics,file_handle)\n",
    "    checked_result.append(r)\n",
    "    with open('checked_results.pkl','wb') as file_handle:\n",
    "        pickle.dump(checked_result,file_handle)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed import Client, progress\n",
    "\n",
    "init = len(checked_result)\n",
    "for r in result[init::]:\n",
    "    select_bimetallic(r)\n",
    "#client = Client()\n",
    "#futures = client.map(select_bimetallic,result[init::])\n",
    "#results = client.gather(futures)\n",
    "#print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def species(r):\n",
    "    a=r.compound.split(str(r.composition[0]))\n",
    "    b=a[1].split(str(r.composition[1]))\n",
    "    a[1] = b[0]\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post bimetallic selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This submodule contains various functions that operate on 'ase.Atoms' \n",
    "objects and bulk structures from pymatgen.\n",
    "'''\n",
    "\n",
    "import scipy\n",
    "from scipy.spatial.qhull import QhullError\n",
    "from ase import Atoms\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "from pymatgen.symmetry.analyzer import SpacegroupAnalyzer\n",
    "from pymatgen.analysis.local_env import VoronoiNN\n",
    "from ase import neighborlist\n",
    "from ase.neighborlist import natural_cutoffs\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from ase import Atoms\n",
    "\n",
    "\n",
    "def find_bulk_cn_dict(bulk_atoms):\n",
    "    struct = AseAtomsAdaptor.get_structure(bulk_atoms)\n",
    "    sga = SpacegroupAnalyzer(struct)\n",
    "    sym_struct = sga.get_symmetrized_structure()\n",
    "    unique_indices = [equ[0] for equ in sym_struct.equivalent_indices]\n",
    "    # Get a dictionary of unique coordination numbers\n",
    "    # for atoms in each structure.\n",
    "    # for example, Pt[1,1,1] would have cn=3 and cn=12\n",
    "    # depends on the Pt atom.\n",
    "    voronoi_nn = VoronoiNN()\n",
    "    cn_dict = {}\n",
    "    for idx in unique_indices:\n",
    "        elem = sym_struct[idx].species_string\n",
    "        if elem not in cn_dict.keys():\n",
    "            cn_dict[elem] = []\n",
    "        cn = voronoi_nn.get_cn(sym_struct, idx, use_weights=True)\n",
    "        cn = float('%.5f' % (round(cn, 5)))\n",
    "        if cn not in cn_dict[elem]:\n",
    "            cn_dict[elem].append(cn)\n",
    "    return cn_dict\n",
    "\n",
    "\n",
    "def find_surface_atoms_indices(bulk_cn_dict, atoms):\n",
    "    struct = AseAtomsAdaptor.get_structure(atoms, cls = None)\n",
    "    voronoi_nn = VoronoiNN()\n",
    "    # Identify index of the surface atoms\n",
    "    indices_list = []\n",
    "    weights = [site.species.weight for site in struct]\n",
    "    center_of_mass = np.average(struct.frac_coords,\n",
    "                                weights=weights, axis=0)\n",
    "    for idx, site in enumerate(struct):\n",
    "        if site.frac_coords[2] > center_of_mass[2]:\n",
    "            try:\n",
    "                cn = voronoi_nn.get_cn(struct, idx, use_weights=True)\n",
    "                cn = float('%.5f' % (round(cn, 5)))\n",
    "                # surface atoms are undercoordinated\n",
    "                if cn < min(bulk_cn_dict[site.species_string]):\n",
    "                    indices_list.append(idx)\n",
    "            except RuntimeError:\n",
    "                # or if pathological error is returned,\n",
    "                # indicating a surface site\n",
    "                indices_list.append(idx)\n",
    "    return indices_list\n",
    "\n",
    "def get_nuclearity_from_atoms(atoms,structure,actives):\n",
    "    #Get surface nuclearity from given Atoms object\n",
    "    slab_atoms = atoms.copy()\n",
    "    #pick surface atoms\n",
    "    bulk_atoms = AseAtomsAdaptor.get_atoms(structure)\n",
    "    bulk_cn = find_bulk_cn_dict(bulk_atoms)\n",
    "    surface_indices = find_surface_atoms_indices(bulk_cn, slab_atoms)\n",
    "\n",
    "    #Generate connectivity matrix\n",
    "    cutOff = natural_cutoffs(slab_atoms)\n",
    "    neighborList = neighborlist.NeighborList(cutOff, self_interaction=False, \n",
    "                                             bothways=True)\n",
    "    neighborList.update(slab_atoms)\n",
    "    connectivity_matrix = neighborList.get_connectivity_matrix()    \n",
    "\n",
    "    #Ignore connectivity with atoms which are not active or on the surface\n",
    "    active_connectivity_matrix = connectivity_matrix.copy()\n",
    "    for atom in slab_atoms:\n",
    "        if atom.symbol not in actives:\n",
    "            active_connectivity_matrix[atom.index,:] = 0\n",
    "            active_connectivity_matrix[:,atom.index] = 0\n",
    "        if atom.index not in surface_indices:\n",
    "            active_connectivity_matrix[atom.index,:] = 0\n",
    "            active_connectivity_matrix[:,atom.index] = 0            \n",
    "    graph = nx.from_scipy_sparse_matrix(active_connectivity_matrix)\n",
    "\n",
    "    #Remove host atoms which are showing up as single atom components\n",
    "    lengths = []\n",
    "    list1 = list(nx.connected_components(graph))\n",
    "    list2 = list1.copy()\n",
    "    for s in list1:\n",
    "        for q in s:\n",
    "            if slab_atoms[q].symbol not in actives:\n",
    "                list2.remove(s)\n",
    "                break\n",
    "            if q not in surface_indices:\n",
    "                list2.remove(s)\n",
    "                break\n",
    "            \n",
    "    #Get list of nuclearities of all active sites on surface\n",
    "    for l in list2:\n",
    "        lengths.append(len(l))\n",
    "    if len(lengths) == 0:\n",
    "        max_nuclearity = 0\n",
    "    else:\n",
    "        max_nuclearity = max(lengths)\n",
    "        \n",
    "    return [max_nuclearity,lengths]\n",
    "\n",
    "def surface_nuclearity_calculator(unitCell_atoms,bulk_structure,actives):\n",
    "    #Check surface nuclearity for given slab and a repeated slab\n",
    "    #Identify infinite or semifinite nuclearity cases\n",
    "    slab_atoms = unitCell_atoms.repeat((2,2,1))\n",
    "    slab_nuclearities = get_nuclearity_from_atoms(slab_atoms,bulk_structure,actives)\n",
    "    unitCell_nuclearities = get_nuclearity_from_atoms(unitCell_atoms,bulk_structure,actives)\n",
    "    if slab_nuclearities[0] == unitCell_nuclearities[0]:\n",
    "        surface_nuclearity = slab_nuclearities\n",
    "    elif slab_nuclearities[0] == 2*unitCell_nuclearities[0]:\n",
    "        surface_nuclearity = ['semi-finite',slab_nuclearities[1]]\n",
    "    elif slab_nuclearities[0] == 4*unitCell_nuclearities[0]:\n",
    "        surface_nuclearity = ['infinite',slab_nuclearities[1]]\n",
    "    else:\n",
    "        surface_nuclearity = [{'unitCell': unitCell_nuclearities[0], \n",
    "                               'slab': slab_nuclearities[0]},\n",
    "                              slab_nuclearities[1]]\n",
    "    return (surface_nuclearity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymatgen.ext.matproj import MPRester\n",
    "from pymatgen.core.surface import generate_all_slabs\n",
    "from ase import Atoms\n",
    "from pymatgen.io.ase import AseAtomsAdaptor\n",
    "\n",
    "def slab_enumeration(bulk_structure):\n",
    "    all_slabs = generate_all_slabs(bulk_structure,2,10,20,\n",
    "                               bonds=None, tol=0.1, ftol=0.1, max_broken_bonds=0,\n",
    "                               lll_reduce=False, center_slab=False, primitive=True,\n",
    "                               max_normal_search=None, symmetrize=False, repair=False,\n",
    "                               include_reconstructions=False, in_unit_planes=False)\n",
    "    return all_slabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import glob\n",
    "\n",
    "actives = ['Pd', 'Pt', 'Rh', 'Ru', 'Ag', 'Ir','Pd\\n', 'Pt\\n', 'Rh\\n', 'Ru\\n', 'Ag\\n', 'Ir\\n']\n",
    "hosts = ['Zn', 'Cd', 'Ga', 'Al', 'In','Zn\\n', 'Cd\\n', 'Ga\\n', 'Al\\n', 'In\\n']\n",
    "def bulk_nuclearity(b):\n",
    "    print(\"working...\")\n",
    "    bulk_atoms = b.atoms(pattern='CONTCAR.relax*', quippy=False, keywords=None, calculator=None)\n",
    "    structure = AseAtomsAdaptor.get_structure(bulk_atoms)\n",
    "    slab_list=slab_enumeration(structure)\n",
    "    slab_atoms_list = []\n",
    "    nuclearity_list = []\n",
    "    for i in range(0,len(b.species)):\n",
    "        if b.species[i] in actives:\n",
    "            x_active = b.stoich[i]\n",
    "    for slab in slab_list:\n",
    "        unitCell_atoms = AseAtomsAdaptor.get_atoms(slab)\n",
    "        nuclearity_result = surface_nuclearity_calculator(unitCell_atoms,structure,list(actives))\n",
    "        slab_atoms_list.append(unitCell_atoms)\n",
    "        nuclearity_list.append([b.compound,b.auid,slab.miller_index,slab.shift,nuclearity_result[0],nuclearity_result[1],x_active])\n",
    "    with open('all_slabs/{}.pkl'.format(b.compound), 'wb') as file_handle:\n",
    "        pickle.dump(slab_list,file_handle)\n",
    "    with open('all_slab_atoms/{}.pkl'.format(b.compound), 'wb') as file_handle:\n",
    "        pickle.dump(slab_atoms_list,file_handle)\n",
    "    with open('all_nuclearities/{}.pkl'.format(b.compound), 'wb') as file_handle:\n",
    "        pickle.dump(nuclearity_list,file_handle)\n",
    "    return nuclearity_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import dask.bag as db\n",
    "init = len(glob.glob('all_nuclearities/*.pkl'))\n",
    "bulk_bag = db.from_sequence(bimetallics[0:3])\n",
    "#bulk_bag = db.from_sequence([1,2,3])\n",
    "#for b in result[init::]:\n",
    "#    bulk_nuclearity(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_bag.map(lambda b: bulk_nuclearity(b)).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import glob\n",
    "\n",
    "output_file = open('nuclearity_all_aflow.xls','w+')\n",
    "for file_handle in glob.glob('all_nuclearities/*.pkl'):\n",
    "    with open(file_handle,'rb'):\n",
    "        nuclearity_list = pickle.load(file_handle)\n",
    "    for nuclearity in nuclearity_list:\n",
    "        for n in nuclearity:\n",
    "            output_file.write(str(n))\n",
    "            output_file.write('\\t')\n",
    "        output_file.write('\\n')\n",
    "output_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
